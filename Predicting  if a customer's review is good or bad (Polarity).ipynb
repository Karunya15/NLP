{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stopwords in c:\\users\\karunya\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (0.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import seaborn as sns\n",
    "from nltk import word_tokenize \n",
    "import string\n",
    "string.punctuation #pre-defined in the string module,containing all the characters as a string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD THE TRAIN AND TEST DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>ReviewText</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13131</td>\n",
       "      <td>Awful! Awful! Awful! No, didn't like it. obvio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13827</td>\n",
       "      <td>John (Ben Chaplin) lonely bank clerk lives sma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3912</td>\n",
       "      <td>Stoic laconic soldier Sergeant Todd (a fine cr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14762</td>\n",
       "      <td>excited see film always heard scary.&lt;br /&gt;&lt;br ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7369</td>\n",
       "      <td>Jungle Fever highly stylized, stereotyped, com...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID                                         ReviewText  Polarity\n",
       "0   13131  Awful! Awful! Awful! No, didn't like it. obvio...         0\n",
       "1   13827  John (Ben Chaplin) lonely bank clerk lives sma...         1\n",
       "2    3912  Stoic laconic soldier Sergeant Todd (a fine cr...         1\n",
       "3   14762  excited see film always heard scary.<br /><br ...         1\n",
       "4    7369  Jungle Fever highly stylized, stereotyped, com...         0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('TrainData.csv', encoding = 'ISO-8859-1')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16750, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>ReviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7868</td>\n",
       "      <td>'The Luzhin Defence' good film fine central pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25016</td>\n",
       "      <td>Cannon Movie Tale worst lot, positive proof fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10668</td>\n",
       "      <td>full length feature film world bridge. found f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14640</td>\n",
       "      <td>Soloist ingredients impress Academy. director,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15018</td>\n",
       "      <td>saw back '94 finally released. Apparently Orio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID                                         ReviewText\n",
       "0    7868  'The Luzhin Defence' good film fine central pe...\n",
       "1   25016  Cannon Movie Tale worst lot, positive proof fi...\n",
       "2   10668  full length feature film world bridge. found f...\n",
       "3   14640  Soloist ingredients impress Academy. director,...\n",
       "4   15018  saw back '94 finally released. Apparently Orio..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('TestData.csv', encoding = 'ISO-8859-1')\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BASIC CHECKS FOR THE DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8250, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train.Polarity.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    8403\n",
      "1    8347\n",
      "Name: Polarity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "Polarity = train.Polarity.value_counts()\n",
    "print(Polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISTRIBUTION OF THE TARGET VARIABLE:'POLARITY' IN THE TRAIN DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\karunya\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "x=train['Polarity'].value_counts()\n",
    "x=x.sort_index()\n",
    "plt.figure(figsize=(10,6))\n",
    "ax= sns.barplot(x.index, x.values, alpha=0.8)\n",
    "plt.title(\"Polarity Distribution\")\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('polarity')\n",
    "rects = ax.patches\n",
    "labels = x.values\n",
    "for rect, label in zip(rects, labels):\n",
    "    height = rect.get_height()\n",
    "    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserID        0\n",
       "ReviewText    0\n",
       "Polarity      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking of null values\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserID        0\n",
       "ReviewText    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text preprocessing helper functions\n",
    "ReviewText = '''Awful! Awful! Awful! No, didn't like it. obvious intent film was: track wheeling dealing \"movers shakers\" produce film. cases, people represent are. didn't need film tell shallow people film industry are. suppose I'm fault really expected something like \"Roman Holiday\".<br /><br />I'm movie-maker take film classes appeared film consisted series 'two-shots' (in main) actors(!) supplied loose plot-line improvise dialogue. Henry Jaglon makes claim along Victoria Foyt actually wrote screenplay impression actors, cognisant general direction film, extemporised dialogue - always successful. case point Ron Silver made remark really didn't flow along line conversation (and I'm going back look it!) Greta Scacchi broke laughter even though supposed serious conversation, Silver's remark non sequitur. get impression one actor deliberately tries 'wrong foot' actor break his/her concentration. Another instance producer tells Silver \"bring &*%#@#^ documents\" (3 times). Silver looked literally lost words. seen one film looked like series drama workshops improvisation awful too!<br /><br />The fact Jaglon able attract Greta Scacchi (no stranger Australia), Ron Silver, Anouk Ami, Maximilian Schell suggests 'slow news week' them. Peter Bogdanovich 'what-the-hell-am-I-doing-here' look face times expected hear say: \"Look, I'm director screenwriter - actor\" - would unnecessary state! Faye Dunaway seemed interested promoting son, Liam. Apart jerky delivery dialogue, hand-held camera became irritating even verisimilitude - suspect \"natural\" dialogue - interest principals became subsumed interest various youths walking along strand trying insinuate shot. least approached Cinema Verite. that, along irritating French singing used mute button, made generally disappointing 90-odd minutes.<br /><br />I think avoid apotheosising films this. Trying see value film little credit order substantiate perceived transcendental level misguided. really nothing avant-garde it. didn't come across work art yet wasn't documentary either. know, mocumentary real test whether entertaining. bored skull! one redeeming feature: pronounced 'Cannes' correctly gave 3/10.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text preprocessing helper functions\n",
    "def clean_text(ReviewText):\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    ReviewText = ReviewText.lower()\n",
    "    ReviewText = re.sub('https?://\\S+|www\\.\\S+', '', ReviewText)\n",
    "    ReviewText = re.sub('<.*?>+', '', ReviewText)\n",
    "    ReviewText = re.sub('[%s]' % re.escape(string.punctuation), '', ReviewText)\n",
    "    ReviewText = re.sub('\\n', '', ReviewText)\n",
    "    ReviewText = re.sub('\\w*\\d\\w*', '', ReviewText)\n",
    "    return ReviewText\n",
    "\n",
    "\n",
    "def text_preprocessing(ReviewText):\n",
    "    \"\"\"\n",
    "    Cleaning and parsing the text.\n",
    "\n",
    "    \"\"\"\n",
    "    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "    nopunc = clean_text(ReviewText)\n",
    "    tokenized_text = tokenizer.tokenize(nopunc)\n",
    "    #remove_stopwords = [w for w in tokenized_text if w not in stopwords.words('english')]\n",
    "    combined_text = ' '.join(tokenized_text)\n",
    "    return combined_text\n",
    "\n",
    "#clean_text() function applies a first round of text cleaning techniques.\n",
    "#the function text_preprocessing() then takes in the processed text from the clean_text() function and applies techniques like tokenization and stop word removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Awful! Awful! Awful! No, didn't like it. obvious intent film was: track wheeling dealing \"movers shakers\" produce film. cases, people represent are. didn't need film tell shallow people film industry are. suppose I'm fault really expected something like \"Roman Holiday\".<br /><br />I'm movie-maker take film classes appeared film consisted series 'two-shots' (in main) actors(!) supplied loose plot-line improvise dialogue. Henry Jaglon makes claim along Victoria Foyt actually wrote screenplay impression actors, cognisant general direction film, extemporised dialogue - always successful. case point Ron Silver made remark really didn't flow along line conversation (and I'm going back look it!) Greta Scacchi broke laughter even though supposed serious conversation, Silver's remark non sequitur. get impression one actor deliberately tries 'wrong foot' actor break his/her concentration. Another instance producer tells Silver \"bring &*%#@#^ documents\" (3 times). Silver looked literally lost words. seen one film looked like series drama workshops improvisation awful too!<br /><br />The fact Jaglon able attract Greta Scacchi (no stranger Australia), Ron Silver, Anouk Ami, Maximilian Schell suggests 'slow news week' them. Peter Bogdanovich 'what-the-hell-am-I-doing-here' look face times expected hear say: \"Look, I'm director screenwriter - actor\" - would unnecessary state! Faye Dunaway seemed interested promoting son, Liam. Apart jerky delivery dialogue, hand-held camera became irritating even verisimilitude - suspect \"natural\" dialogue - interest principals became subsumed interest various youths walking along strand trying insinuate shot. least approached Cinema Verite. that, along irritating French singing used mute button, made generally disappointing 90-odd minutes.<br /><br />I think avoid apotheosising films this. Trying see value film little credit order substantiate perceived transcendental level misguided. really nothing avant-garde it. didn't come across work art yet wasn't documentary either. know, mocumentary real test whether entertaining. bored skull! one redeeming feature: pronounced 'Cannes' correctly gave 3/10.\n"
     ]
    }
   ],
   "source": [
    "print(ReviewText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the cleaning function to both test and training datasets\n",
    "\n",
    "train['text_clean'] = train['ReviewText'].apply(str).apply(lambda x: text_preprocessing(x))\n",
    "test['text_clean'] = test['ReviewText'].apply(str).apply(lambda x: text_preprocessing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = WordNetLemmatizer()\n",
    "#lemmetizing to analyse the words as a single item\n",
    "\n",
    "def own_analyser(review):\n",
    "    review = review.split()\n",
    "    for i in range(0,len(review)):\n",
    "        k = review.pop(0)\n",
    "        if k not in string.punctuation:\n",
    "                review.append(lm.lemmatize(k).lower())    \n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [w, f, u, l,  , w, f, u, l,  , w, f, u, l,  , ...\n",
       "1        [j, h, n,  , b, e, n,  , c, h, p, l, n,  , l, ...\n",
       "2        [c,  , l, c, n, c,  , l, e, r,  , e, r, g, e, ...\n",
       "3        [e, x, c, e,  , e, e,  , f, l,  , l, w,  , h, ...\n",
       "4        [j, u, n, g, l, e,  , f, e, v, e, r,  , h, g, ...\n",
       "                               ...                        \n",
       "16745    [l, k, e,  , q, u, e,  , n, r,  , f, r,  , p, ...\n",
       "16746    [h, u, g, h,  , e, q, u, e, l,  , r,  , e, n, ...\n",
       "16747    [l,  , l, k, e,  , h, e, r, e,  , c, r,  , f, ...\n",
       "16748    [h, g, h, l,  , r, e, c, e, n,  , f, l,  , e, ...\n",
       "16749    [b, l, l,  , e,  , b, c, k,  , e,  , e, v, l, ...\n",
       "Name: text_clean, Length: 16750, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = stopwords.words('english')\n",
    "train['text_clean'].apply(lambda x: [item for item in x if item not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [h, e,  , l, u, z, h, n,  , e, f, e, n, c, e, ...\n",
       "1       [c, n, n, n,  , v, e,  , l, e,  , w, r,  , l, ...\n",
       "2       [f, u, l, l,  , l, e, n, g, h,  , f, e, u, r, ...\n",
       "3       [l,  , n, g, r, e, e, n,  , p, r, e,  , c, e, ...\n",
       "4       [w,  , b, c, k,  , f, n, l, l,  , r, e, l, e, ...\n",
       "                              ...                        \n",
       "8245    [v, c,  , r, c, h, r,  , r, e, f, u,  , b,  , ...\n",
       "8246    [p, n, c,  , n, e, v, e, r,  , g,  , g,  , h, ...\n",
       "8247    [p, l, n, g,  , k, l, e, h, p, p, e, r,  , c, ...\n",
       "8248    [u,  , n, e,  , w, r,  , v, e,  , e, v, e, r, ...\n",
       "8249    [w, n, e, r, f, u, l,  , v, e,  , l,  , w,  , ...\n",
       "Name: text_clean, Length: 8250, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['text_clean'].apply(lambda x: [item for item in x if item not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13131</td>\n",
       "      <td>0</td>\n",
       "      <td>awful awful awful no didnt like it obvious int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13827</td>\n",
       "      <td>1</td>\n",
       "      <td>john ben chaplin lonely bank clerk lives small...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3912</td>\n",
       "      <td>1</td>\n",
       "      <td>stoic laconic soldier sergeant todd a fine cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14762</td>\n",
       "      <td>1</td>\n",
       "      <td>excited see film always heard scarywhats inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7369</td>\n",
       "      <td>0</td>\n",
       "      <td>jungle fever highly stylized stereotyped comes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  Polarity                                         text_clean\n",
       "0   13131         0  awful awful awful no didnt like it obvious int...\n",
       "1   13827         1  john ben chaplin lonely bank clerk lives small...\n",
       "2    3912         1  stoic laconic soldier sergeant todd a fine cre...\n",
       "3   14762         1  excited see film always heard scarywhats inter...\n",
       "4    7369         0  jungle fever highly stylized stereotyped comes..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.drop(['ReviewText'], axis=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7868</td>\n",
       "      <td>the luzhin defence good film fine central perf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25016</td>\n",
       "      <td>cannon movie tale worst lot positive proof fiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10668</td>\n",
       "      <td>full length feature film world bridge found fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14640</td>\n",
       "      <td>soloist ingredients impress academy director j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15018</td>\n",
       "      <td>saw back finally released apparently orion pic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID                                         text_clean\n",
       "0    7868  the luzhin defence good film fine central perf...\n",
       "1   25016  cannon movie tale worst lot positive proof fiv...\n",
       "2   10668  full length feature film world bridge found fi...\n",
       "3   14640  soloist ingredients impress academy director j...\n",
       "4   15018  saw back finally released apparently orion pic..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test.drop(['ReviewText'], axis=1)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = WordNetLemmatizer()\n",
    "#lemmetizing to analyse the words as a single item\n",
    "\n",
    "def own_analyser(review):\n",
    "    review = review.split()\n",
    "    for i in range(0,len(review)):\n",
    "        k = review.pop(0)\n",
    "        if k not in string.punctuation:\n",
    "                review.append(lm.lemmatize(k).lower())    \n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train.text_clean\n",
    "y=train.Polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "phrase_train,phrase_test,sentiment_train,sentiment_test = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL BUILDING FOR THE TRAIN DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✔ NAIVE BAYES (MULTINOMIAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using pipeline feature of sklearn \n",
    "#pipeline feature is good to use for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([('BOW',CountVectorizer(analyzer=own_analyser)),\n",
    "                    ('tfidf',TfidfTransformer()),\n",
    "                    ('classifier',MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('BOW',\n",
       "                 CountVectorizer(analyzer=<function own_analyser at 0x1264BB68>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('classifier', MultinomialNB())])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(phrase_train,sentiment_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(phrase_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.86      2550\n",
      "           1       0.87      0.84      0.86      2475\n",
      "\n",
      "    accuracy                           0.86      5025\n",
      "   macro avg       0.86      0.86      0.86      5025\n",
      "weighted avg       0.86      0.86      0.86      5025\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(sentiment_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✔ NAIVE BAYES (BERNOULLI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline0 = Pipeline([('BOW',CountVectorizer(analyzer=own_analyser)),\n",
    "                    ('tfidf',TfidfTransformer()),\n",
    "                    ('classifier',BernoulliNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('BOW',\n",
       "                 CountVectorizer(analyzer=<function own_analyser at 0x1264BB68>)),\n",
       "                ('tfidf', TfidfTransformer()), ('classifier', BernoulliNB())])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline0.fit(phrase_train,sentiment_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsBernoulli = pipeline0.predict(phrase_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85      2550\n",
      "           1       0.87      0.80      0.83      2475\n",
      "\n",
      "    accuracy                           0.84      5025\n",
      "   macro avg       0.84      0.84      0.84      5025\n",
      "weighted avg       0.84      0.84      0.84      5025\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(sentiment_test,predictionsBernoulli))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✔ LINEAR SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline1 = Pipeline([('BOW',CountVectorizer(analyzer=own_analyser)),\n",
    "                    ('tfidf',TfidfTransformer()),\n",
    "                    ('classifier',LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('BOW',\n",
       "                 CountVectorizer(analyzer=<function own_analyser at 0x1264BB68>)),\n",
       "                ('tfidf', TfidfTransformer()), ('classifier', LinearSVC())])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline1.fit(phrase_train,sentiment_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsSVC = pipeline1.predict(phrase_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.88      2550\n",
      "           1       0.87      0.90      0.88      2475\n",
      "\n",
      "    accuracy                           0.88      5025\n",
      "   macro avg       0.88      0.88      0.88      5025\n",
      "weighted avg       0.88      0.88      0.88      5025\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(sentiment_test,predictionsSVC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✔ LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline2 = Pipeline([('BOW',CountVectorizer(analyzer=own_analyser)),\n",
    "                    ('tfidf',TfidfTransformer()),\n",
    "                    ('classifier',LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('BOW',\n",
       "                 CountVectorizer(analyzer=<function own_analyser at 0x1264BB68>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('classifier', LogisticRegression())])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline2.fit(phrase_train,sentiment_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsLogisticR = pipeline2.predict(phrase_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.88      2550\n",
      "           1       0.86      0.90      0.88      2475\n",
      "\n",
      "    accuracy                           0.88      5025\n",
      "   macro avg       0.88      0.88      0.88      5025\n",
      "weighted avg       0.88      0.88      0.88      5025\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(sentiment_test,predictionsLogisticR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✔ RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline3 = Pipeline([('BOW',CountVectorizer(analyzer=own_analyser)),\n",
    "                    ('tfidf',TfidfTransformer()),\n",
    "                    ('classifier',RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('BOW',\n",
       "                 CountVectorizer(analyzer=<function own_analyser at 0x1264BB68>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('classifier', RandomForestClassifier())])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline3.fit(phrase_train,sentiment_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsLogisticR = pipeline3.predict(phrase_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      2550\n",
      "           1       0.83      0.81      0.82      2475\n",
      "\n",
      "    accuracy                           0.82      5025\n",
      "   macro avg       0.82      0.82      0.82      5025\n",
      "weighted avg       0.82      0.82      0.82      5025\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(sentiment_test,predictionsLogisticR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we get the highest accuracy of 88% from LinearSVC and Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPLYING IN TEST DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>UserID</th>\n",
       "      <th>ReviewText</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7868</td>\n",
       "      <td>'The Luzhin Defence' good film fine central pe...</td>\n",
       "      <td>the luzhin defence good film fine central perf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25016</td>\n",
       "      <td>Cannon Movie Tale worst lot, positive proof fi...</td>\n",
       "      <td>cannon movie tale worst lot positive proof fiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10668</td>\n",
       "      <td>full length feature film world bridge. found f...</td>\n",
       "      <td>full length feature film world bridge found fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>14640</td>\n",
       "      <td>Soloist ingredients impress Academy. director,...</td>\n",
       "      <td>soloist ingredients impress academy director j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>15018</td>\n",
       "      <td>saw back '94 finally released. Apparently Orio...</td>\n",
       "      <td>saw back finally released apparently orion pic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  UserID                                         ReviewText  \\\n",
       "0           0    7868  'The Luzhin Defence' good film fine central pe...   \n",
       "1           1   25016  Cannon Movie Tale worst lot, positive proof fi...   \n",
       "2           2   10668  full length feature film world bridge. found f...   \n",
       "3           3   14640  Soloist ingredients impress Academy. director,...   \n",
       "4           4   15018  saw back '94 finally released. Apparently Orio...   \n",
       "\n",
       "                                          text_clean  \n",
       "0  the luzhin defence good film fine central perf...  \n",
       "1  cannon movie tale worst lot positive proof fiv...  \n",
       "2  full length feature film world bridge found fi...  \n",
       "3  soloist ingredients impress academy director j...  \n",
       "4  saw back finally released apparently orion pic...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test_df.csv', encoding = 'ISO-8859-1')\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7868</td>\n",
       "      <td>the luzhin defence good film fine central perf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25016</td>\n",
       "      <td>cannon movie tale worst lot positive proof fiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10668</td>\n",
       "      <td>full length feature film world bridge found fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14640</td>\n",
       "      <td>soloist ingredients impress academy director j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15018</td>\n",
       "      <td>saw back finally released apparently orion pic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID                                         text_clean\n",
       "0    7868  the luzhin defence good film fine central perf...\n",
       "1   25016  cannon movie tale worst lot positive proof fiv...\n",
       "2   10668  full length feature film world bridge found fi...\n",
       "3   14640  soloist ingredients impress academy director j...\n",
       "4   15018  saw back finally released apparently orion pic..."
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_d = test.drop(['Unnamed: 0','ReviewText'], axis=1)\n",
    "test_d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserID        0\n",
       "text_clean    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_d.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_d.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserID        0\n",
       "text_clean    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## applying LinearSVC model with highest accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = pipeline1.predict(test_data['text_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "User_ID = test_data['UserID'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8249,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the dataframe formation with predicted response for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'UserID':User_ID,'Polarity':test_predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10668</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14640</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8244</th>\n",
       "      <td>11802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8245</th>\n",
       "      <td>8160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8246</th>\n",
       "      <td>3499</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8247</th>\n",
       "      <td>13899</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8248</th>\n",
       "      <td>19149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8249 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      UserID  Polarity\n",
       "0       7868         1\n",
       "1      25016         0\n",
       "2      10668         1\n",
       "3      14640         0\n",
       "4      15018         0\n",
       "...      ...       ...\n",
       "8244   11802         0\n",
       "8245    8160         1\n",
       "8246    3499         1\n",
       "8247   13899         0\n",
       "8248   19149         1\n",
       "\n",
       "[8249 rows x 2 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv file containing UserID and predicted Response in a csv file for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('SUBMISSION.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
